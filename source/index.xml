<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sources on MLOS</title>
    <link>https://microsoft.github.io/MLOS/source/</link>
    <description>Recent content in Sources on MLOS</description>
    <generator>Hugo -- gohugo.io</generator>
    
	<atom:link href="https://microsoft.github.io/MLOS/source/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://microsoft.github.io/MLOS/source/Mlos.NetCore/Doc/SharedChannelScaleout/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://microsoft.github.io/MLOS/source/Mlos.NetCore/Doc/SharedChannelScaleout/</guid>
      <description>Shared Channel Scaleout Document contains results of the improvement in the shared communication channel. We specifically address lack of the scalability issue. The channel does not scale well with increasing number of readers and writers operating on the same channel instance.
Benchmark The benchmark is implemented in Mlos.NetCore.Benchmark project
Benchmark:
 $(MLOSROOT)\MLOS\out\obj\Source\Mlos.NetCore.Benchmark\obj\amd64\Mlos.NetCore.Benchmark.exe -i &amp;ndash;filter SharedChannelReaderScaleOutBenchmarks
 Results Hyper-threading is disabled.
 Intel E5-2670 v3 @ 2.30 GHz:    ReaderCount Mean[B] Mean[I] Error[B] Error[I] StdDev[B] StdDev[I] Allocated     1 830.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://microsoft.github.io/MLOS/source/Mlos.Python/Docs/BayesianOptimizerArchitecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://microsoft.github.io/MLOS/source/Mlos.Python/Docs/BayesianOptimizerArchitecture/</guid>
      <description>Bayesian Optimizer Architecture Components  Surrogate Models Utility Functions Numeric Optimizers Experiment Designer Bayesian Optimizer  Other Classes  Hypergrids Optimization Problems  Hypergrids Hypergrids are used to describe multidimensional spaces comprized of Continuous, Discrete, Ordinal, or Categorical dimensions.
All optimizers we have reviewed to date (Hypermapper, SMAC, bayesopt, and scikit-learn) optimizers implement their own notion of a search space.
Hypergrids are meant to provide a superset of their functionalities. They further allow us to express hierarchical search spaces, where some parameters only become meaningful if some other parameter (e.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://microsoft.github.io/MLOS/source/Mlos.Python/Docs/BayesianOptimizerV1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://microsoft.github.io/MLOS/source/Mlos.Python/Docs/BayesianOptimizerV1/</guid>
      <description>Bayesian Optimizer V1 The goal of this document is to describe the architecture and inner workings of a Bayesian Optimizer.
Components The following components will be necessary:
 Experiment Observation Storage (Table in SQL Server) Bayesian Optimizer Surrogate Models  Architecture TODO: describe how we will use the technologies:
 Docker (K8S?) SQL Server Python ML.Net SQL DB RPC vs. gRPC  Obviously an experiment and the corresponding bayesian optimizer have to be compatible so that the observations generated by the experiment are within the optimizers observation space.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://microsoft.github.io/MLOS/source/Mlos.Python/Docs/OptimizerMonitoring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://microsoft.github.io/MLOS/source/Mlos.Python/Docs/OptimizerMonitoring/</guid>
      <description>Optimizer Monitoring Motivation The goal of this document is to outline the process of monitoring the optimizers, enumerate the metrics we wish to collect and the tools required to do so.
What we wish to monitor For each optimizer we should be able to:
 View it&amp;rsquo;s current configuration (done). View all the data that it was trained on. View the state of the surrogate models:  Have they been fitted?</description>
    </item>
    
    <item>
      <title></title>
      <link>https://microsoft.github.io/MLOS/source/Mlos.Python/Docs/SimpleImportGraph/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://microsoft.github.io/MLOS/source/Mlos.Python/Docs/SimpleImportGraph/</guid>
      <description>digraph dfd2 {node[shape=record]&amp;quot;BayesianOptimizer.py&amp;quot; -&amp;gt; &amp;quot;OptimizationProblem.py&amp;quot;&amp;quot;HomogeneousRandomForestRegressionModel.py&amp;quot; -&amp;gt; &amp;quot;DecisionTreeRegressionModel.py&amp;quot;&amp;quot;BayesianOptimizer.py&amp;quot; -&amp;gt; &amp;quot;OptimizerInterface.py&amp;quot;&amp;quot;ExperimentDesigner.py&amp;quot; -&amp;gt; &amp;quot;RegressionModel.py&amp;quot;&amp;quot;OptimizerInterface.py&amp;quot; -&amp;gt; &amp;quot;OptimizationProblem.py&amp;quot;&amp;quot;BayesianOptimizer.py&amp;quot; -&amp;gt; &amp;quot;ExperimentDesigner.py&amp;quot;&amp;quot;HomogeneousRandomForestRegressionModel.py&amp;quot; -&amp;gt; &amp;quot;Prediction.py&amp;quot;&amp;quot;DecisionTreeRegressionModel.py&amp;quot; -&amp;gt; &amp;quot;RegressionModel.py&amp;quot;&amp;quot;ExperimentDesigner.py&amp;quot; -&amp;gt; &amp;quot;ConfidenceBoundUtilityFunction.py&amp;quot;&amp;quot;RandomSearchOptimizer.py&amp;quot; -&amp;gt; &amp;quot;OptimizationProblem.py&amp;quot;&amp;quot;HomogeneousRandomForestRegressionModel.py&amp;quot; -&amp;gt; &amp;quot;RegressionModel.py&amp;quot;&amp;quot;DecisionTreeRegressionModel.py&amp;quot; -&amp;gt; &amp;quot;Prediction.py&amp;quot;&amp;quot;ExperimentDesigner.py&amp;quot; -&amp;gt; &amp;quot;RandomSearchOptimizer.py&amp;quot;&amp;quot;ExperimentDesigner.py&amp;quot; -&amp;gt; &amp;quot;OptimizationProblem.py&amp;quot;&amp;quot;BayesianOptimizer.py&amp;quot; -&amp;gt; &amp;quot;HomogeneousRandomForestRegressionModel.py&amp;quot;}</description>
    </item>
    
    <item>
      <title></title>
      <link>https://microsoft.github.io/MLOS/source/Mlos.Python/mlos/Examples/SmartCache/OverviewOfCachingStrategies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://microsoft.github.io/MLOS/source/Mlos.Python/mlos/Examples/SmartCache/OverviewOfCachingStrategies/</guid>
      <description>Overview of Caching Strategies and Algorithms Goal The objective of this document is to describe various approaches to caching. The intent is to then implement a number of paramiterized caching algorithms and allow MLOS to select between them on a per-workload basis.
Links A loose list of sources consulted in this survey:
 https://medium.com/datadriveninvestor/all-things-caching-use-cases-benefits-strategies-choosing-a-caching-technology-exploring-fa6c1f2e93aa https://en.wikipedia.org/wiki/Cache_replacement_policies  Potential Objectives  average retrieval time/cost/latency (or other statistics: percentiles, CI&amp;rsquo;s etc) hit ratio and miss ratio cache hit latency metrics (in case of a hit) data staleness metrics (distribution of time since last usage among all cache entries)  Plausible Implementations/Approaches  FIFO - a queue and a hash-map would work.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://microsoft.github.io/MLOS/source/Mlos.Python/mlos/Spaces/HypergridAdapters/AboutHypergridAdapters/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://microsoft.github.io/MLOS/source/Mlos.Python/mlos/Spaces/HypergridAdapters/AboutHypergridAdapters/</guid>
      <description>Hypergrid Adapters Motivation Categorical to numeric projections The goal of adapters is to make a broader class of hypergrids compatible with any surrogate model. The chief problem in absence of adapters is that some models (RERF, DecisionTreeRegressionModel) can only operate on numeric datatypes, but the configuration for many components includes strings, and booleans as well. A suitable adapter will map such categorical dimensions into numeric ones and allow transparent projection of observations and suggestions between the components and the regression models.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://microsoft.github.io/MLOS/source/Mlos.Streaming/Doc/AggregateStreaming/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://microsoft.github.io/MLOS/source/Mlos.Streaming/Doc/AggregateStreaming/</guid>
      <description>Aggregates on the telemetry streams Intro Processing models     Single return value Multiple return values     Pull/Synchronous/Interactive T IEnumerable&amp;lt;T&amp;gt;   Push/Asynchronous/Reactive Task&amp;lt;T&amp;gt; IObservable&amp;lt;T&amp;gt;    MLOS Telemetry channel Processing events   why not async:
 introduces dedicated processing tasks additional latency introduced by AsyncQueue    why we need a push model
  Linq operators on observable streams Merging streams operator Collecting the results  in progress  Performance improvements  in progress  </description>
    </item>
    
  </channel>
</rss>